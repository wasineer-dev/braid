{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wasineer-dev/braid/blob/develop/inputBioPlex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-r9jfe8z7Yw",
        "outputId": "77308714-9fb6-41ff-c51b-1f5facc13058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of baits =  5157\n",
            "Number of preys =  8800\n",
            "Number of proteins =  10961\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from scipy.ndimage import gaussian_filter1d \n",
        "from time import time as timer\n",
        "\n",
        "class CountBioplexMatrix:\n",
        "\n",
        "    def __init__(self, filePath, bait_inds, incidence):\n",
        "        Nd, Np = incidence.shape\n",
        "        nProteins = Np\n",
        "        self.nProteins = Np\n",
        "        self.mObserved = np.zeros(shape=(nProteins, nProteins), dtype=int)\n",
        "        for i, bait in zip(range(len(bait_inds)), bait_inds):\n",
        "            for j in range(nProteins):\n",
        "                if incidence[i,j]:\n",
        "                    self.mObserved[j,:] += incidence[i,:] \n",
        "                    self.mObserved[:,j] += incidence[i,:]\n",
        "    \n",
        "        self.mTrials = np.zeros(shape=(nProteins, nProteins), dtype=int)\n",
        "        for i, bait in zip(range(len(bait_inds)), bait_inds):\n",
        "            for j in range(nProteins):\n",
        "                if incidence[i,j]:\n",
        "                    self.mTrials[j,:] += np.ones(nProteins, dtype=int) \n",
        "                    self.mTrials[:,j] += np.ones(nProteins, dtype=int)\n",
        "                \n",
        "        for i in range(nProteins):\n",
        "            assert(np.sum(self.mTrials[i,:]) == np.sum(self.mTrials[:,i]))\n",
        "\n",
        "        #\n",
        "        # Create the adjacency list\n",
        "        #\n",
        "        self.lstAdjacency = {}\n",
        "        for i in np.arange(nProteins):\n",
        "            self.lstAdjacency[i] = set()\n",
        "            for j in np.arange(nProteins):\n",
        "                t = self.mTrials[i][j]\n",
        "                if (i < j):\n",
        "                    s = self.mObserved[i][j] \n",
        "                else:\n",
        "                    s = self.mObserved[j][i] \n",
        "                assert(s <= t)\n",
        "                if (i != j and t > 0):    \n",
        "                    self.lstAdjacency[i].add(j)\n",
        "                    \n",
        "#\n",
        "# TODO: cpmFunc can be countSpokeModel or countMatrixModel\n",
        "#\n",
        "class CInputBioplex:\n",
        "\n",
        "    def __init__(self, filePath, cpmFunc):\n",
        "        super().__init__()\n",
        "\n",
        "        df = pd.read_csv(filePath, sep='\\t')\n",
        "        #df_filtered = df[df.apply(lambda x: not x['bait_symbol'].isnumeric() and x['bait_symbol'] != \"nan\", axis=1)]\n",
        "        #df_filtered = df_filtered[df_filtered.apply(lambda x: isinstance(x['symbol'], str) and not x['symbol'].isnumeric(), axis=1)]\n",
        "\n",
        "        df_filtered = df\n",
        "        bait_list = np.array(df_filtered['Bait Symbol'], dtype='U21')\n",
        "        prey_list = np.array(df_filtered['Prey Symbol'], dtype='U21')\n",
        "\n",
        "        proteins_list = np.append(bait_list, prey_list)\n",
        "            \n",
        "        self.nProteins = len(np.unique(proteins_list))\n",
        "        nProteins = self.nProteins\n",
        "\n",
        "        print('Number of baits = ', len(np.unique(bait_list)))\n",
        "        print('Number of preys = ', len(np.unique(prey_list)))\n",
        "        print('Number of proteins = ', nProteins)\n",
        "\n",
        "        self.aSortedProteins = np.sort(np.unique(proteins_list))  # sorted proteins list\n",
        "        \n",
        "        bait_inds = np.searchsorted(self.aSortedProteins, np.array(bait_list, dtype='U21'))\n",
        "        prey_inds = np.searchsorted(self.aSortedProteins, np.array(prey_list, dtype='U21'))\n",
        "\n",
        "\n",
        "        nBaits = len(np.unique(bait_list))\n",
        "        self.incidence = np.zeros((nBaits, nProteins), dtype=int)\n",
        "        aSortedBaits = np.sort(np.unique(bait_list))\n",
        "        inds = np.searchsorted(aSortedBaits, np.array(bait_list, dtype='U21'))\n",
        "        for bait, prey in zip(inds, prey_inds):\n",
        "            self.incidence[bait][prey] = 1\n",
        "        del df\n",
        "\n",
        "        self.observationG = cpmFunc(filePath, range(nBaits), self.incidence)\n",
        "\n",
        "    def writeCluster2File(self, baseName, matQ, indVec):\n",
        "        nRows, nCols = matQ.shape\n",
        "        filePath = baseName + \".tab\"\n",
        "        with open(filePath, \"w\") as fh:\n",
        "            for i in range(nRows):\n",
        "                ind = indVec[i]\n",
        "                fh.write(str(self.aSortedProteins[i]) + '\\t' + str(indVec[i]) + '\\t' + str(max(matQ[ind])) + '\\n')\n",
        "            fh.close()\n",
        "        with open(\"bioplex_out.csv\", \"w\") as fh:\n",
        "            for k in range(nCols):\n",
        "                for i in range(nRows):\n",
        "                    ind = indVec[i]\n",
        "                    if (ind == k):\n",
        "                        fh.write(self.aSortedProteins[i] + '\\t')\n",
        "                fh.write('\\n')\n",
        "            fh.close()\n",
        "\n",
        "    def writeLabel2File(self, indVec):\n",
        "        clusters = {}\n",
        "        for i,k in enumerate(indVec):\n",
        "            if k not in clusters.keys():\n",
        "                clusters[k] = set()\n",
        "            clusters[k].add(i)\n",
        "\n",
        "        with open(\"bioplex_out.csv\", \"w\") as fh:\n",
        "            for i, k in enumerate(clusters):\n",
        "                for v in clusters[k]:\n",
        "                    fh.write(self.aSortedProteins[v] + '\\t')\n",
        "                fh.write('\\n')\n",
        "            fh.close()\n",
        "            \n",
        "def clustering(inputSet, Nk, psi, fileName):\n",
        "    fn = 0.8\n",
        "    fp = 0.04\n",
        "    nProteins = inputSet.observationG.nProteins\n",
        "    cmfa = CMeanFieldAnnealing(nProteins, Nk) # default\n",
        "\n",
        "    funcInfer = cmfa\n",
        "\n",
        "    ts = timer()\n",
        "    # alpha = 1e-2\n",
        "    funcInfer.estimate(inputSet.observationG, nProteins, Nk, psi) \n",
        "    te = timer()\n",
        "    print(\"Time running MFA: \", te-ts)\n",
        "\n",
        "    funcInfer.find_argmax()\n",
        "    inputSet.writeCluster2File(fileName, funcInfer.mIndicatorQ, funcInfer.indicatorVec)\n",
        "\n",
        "bioPlex2 = CInputBioplex(\"/content/drive/MyDrive/BioPlex_2.0_293T_DirectedEdges.tsv\", CountBioplexMatrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wLUArVyj7RG0"
      },
      "outputs": [],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_1UxRxR-4C0x"
      },
      "outputs": [],
      "source": [
        "MAX_ITERATION = 20\n",
        "\n",
        "class CMeanFieldAnnealing:\n",
        "\n",
        "    def __init__(self, Nproteins, Nk):\n",
        "        self.lstExpectedLikelihood = []\n",
        "        self.mIndicatorQ = np.zeros((Nproteins, Nk), dtype=float)\n",
        "\n",
        "    def tf_annealing(self, mix_p, mObservationG, Nproteins, Nk, psi):\n",
        "\n",
        "        matA = tf.convert_to_tensor(mObservationG.mTrials - mObservationG.mObserved, dtype=tf.float32)\n",
        "        matB = tf.convert_to_tensor(psi*mObservationG.mObserved, dtype=tf.float32)\n",
        "        tfArray = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
        "        for i in range(Nproteins):\n",
        "            tfArray = tfArray.write(i, self.mIndicatorQ[i])\n",
        "        \n",
        "        gamma = 1000.0\n",
        "        nIteration = 0\n",
        "        while(nIteration < MAX_ITERATION and gamma > 1.0):\n",
        "            for i in range(Nproteins):        \n",
        "                tQ = tfArray.stack()\n",
        "                fn_out = tf.tensordot(matA[i], tQ, axes=1) \n",
        "                fp_out = tf.tensordot(matB[i], 1.0 - tQ, axes=1)\n",
        "\n",
        "                mLogLikelihood = fn_out + fp_out\n",
        "                tfArray = tfArray.write(i, tf.nn.softmax(-gamma*mLogLikelihood))\n",
        "\n",
        "            nIteration += 1\n",
        "            gamma = gamma - 100.0\n",
        "        print(\"Initialize with MFA: num. iterations = \", nIteration)\n",
        "        self.mIndicatorQ = tfArray.stack().numpy()\n",
        "\n",
        "    def estimate(self, mObservationG, Nproteins, Nk, psi):\n",
        "        \n",
        "        print('psi = ', psi)\n",
        "\n",
        "        mix_p = (1.0/float(Nk))*np.ones(Nk, dtype=float)\n",
        "        alpha1 = 1e-8\n",
        "        for i in range(Nproteins):\n",
        "            self.mIndicatorQ[i] = np.random.uniform(0.0, 1.0, size=Nk)\n",
        "            self.mIndicatorQ[i] = (self.mIndicatorQ[i] + alpha1)/(np.sum(self.mIndicatorQ[i]) + alpha1*Nproteins)\n",
        "\n",
        "        self.tf_annealing(mix_p, mObservationG, Nproteins, Nk, psi)\n",
        "\n",
        "    def find_argmax(self):\n",
        "        N = np.size(self.mIndicatorQ, axis=0)\n",
        "        k = np.size(self.mIndicatorQ, axis=1)\n",
        "        self.indicatorVec = np.argmax(self.mIndicatorQ, axis=1)\n",
        "        \n",
        "    def computeErrorRate(self, mObservationG, Nproteins):\n",
        "        \n",
        "        self.find_argmax()\n",
        "\n",
        "        nClusters = len(np.unique(self.indicatorVec))\n",
        "        print(\"Number of clusters used: \" + str(nClusters))\n",
        "\n",
        "        countFn = 0\n",
        "        countFp = 0\n",
        "        sumSameCluster = 0\n",
        "        sumDiffCluster = 0\n",
        "        for i in range(Nproteins):\n",
        "            for j in mObservationG.lstAdjacency[i]:\n",
        "                t = mObservationG.mTrials[i][j]\n",
        "                s = mObservationG.mObserved[i][j]\n",
        "                assert(s <= t)\n",
        "                if (self.indicatorVec[i] == self.indicatorVec[j]):\n",
        "                    countFn += (t - s)\n",
        "                    sumSameCluster += t\n",
        "                else:\n",
        "                    countFp += s\n",
        "                    sumDiffCluster += t\n",
        "\n",
        "        counts = countFn + countFp\n",
        "        fn = 0.0\n",
        "        fp = 0.0\n",
        "        if (sumSameCluster > 0):\n",
        "            fn = float(countFn)/float(sumSameCluster)\n",
        "        if (sumDiffCluster > 0):\n",
        "            fp = float(countFp)/float(sumDiffCluster)\n",
        "        likelihood = countFn*(-np.log(fn) + np.log(1.0 - fp)) + countFp*(-np.log(fp) + np.log(1.0 - fn)) \n",
        "        for i in range(Nproteins):\n",
        "            for j in mObservationG.lstAdjacency[i]:\n",
        "                t = mObservationG.mTrials[i][j]\n",
        "                s = mObservationG.mObserved[i][j]\n",
        "                likelihood += -s*(np.log(1.0-fn)) - (t-s)*(np.log(1.0-fp))\n",
        "        return (fn, fp, counts, likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXOA0P5R9AK4",
        "outputId": "1eea6d08-f56c-428f-f62f-41eb3c0e545e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "psi =  0.3\n"
          ]
        }
      ],
      "source": [
        "def hill_climbing(inputSet, Nk):\n",
        "\n",
        "    nProteins = inputSet.observationG.nProteins\n",
        "    cmfa = CMeanFieldAnnealing(nProteins, Nk) # default      \n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      cmfa.estimate(inputSet.observationG, nProteins, Nk, 0.3)\n",
        "    (fn, fp, errs, f_last) = cmfa.computeErrorRate(inputSet.observationG, nProteins)\n",
        "    x_values = np.arange(1.0, 10.5, 0.2)\n",
        "    y_values = np.zeros(len(x_values), dtype=float)\n",
        "    aics = np.zeros(len(x_values), dtype=float) \n",
        "    for i, psi in enumerate(x_values):\n",
        "        ts = timer()\n",
        "        with tf.device('/device:GPU:0'):\n",
        "          f_value = cmfa.estimate(inputSet.observationG, nProteins, Nk, psi) \n",
        "        te = timer()\n",
        "        print(\"Time running MFA: \", te-ts)\n",
        "        print(\"x = \", psi, \"f(x) = \", f_value)\n",
        "        (fn, fp, errs, likelihood) = cmfa.computeErrorRate(inputSet.observationG, nProteins)\n",
        "        print(\"\\tLikelihood =\", likelihood)\n",
        "        y_values[i] = likelihood\n",
        "        aics[i] = (Nk - likelihood)/(Nk - f_last)\n",
        "        f_last = likelihood\n",
        "    return (x_values, aics)\n",
        "\n",
        "\n",
        "x_values, aics = hill_climbing(bioPlex2, 700)\n",
        "\n",
        "aics_filter = gaussian_filter1d(aics, 1)\n",
        "aics_d2 = np.gradient(np.gradient(aics_filter))\n",
        "infls = np.where(np.diff(np.sign(aics_d2)))[0]\n",
        "print(\"psi = \", x_values[infls])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IQD-Y533eQW"
      },
      "outputs": [],
      "source": [
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbaLyqkW4PlI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x_values, aics_filter, label='AIC Filter')\n",
        "plt.plot(x_values, aics, label='AIC')\n",
        "for i, infl in enumerate(infls):\n",
        "    plt.axvline(x=x_values[infl], color='k')\n",
        "plt.legend(bbox_to_anchor=(1.5, 1.0))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMV2/3QyFRr09vmeFsjbm+b",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "mount_file_id": "1eJ5ssrsKFPCUP4XtOXXJjWvOb2rV-de1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit ('anaconda3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "96762580dc771c728ac9a1b8aa29a3a420bc09545a8c1a32553175fbb1f6eb2a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
